{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8362f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c066c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training = torchvision.datasets.FashionMNIST('./data',train=True,download=True)\n",
    "Testing =  torchvision.datasets.FashionMNIST('./data',train=False,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cfcf332",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = torch.unsqueeze(Training.data,1)/255\n",
    "training_values = torch.LongTensor(Training.targets)\n",
    "\n",
    "testing = torch.unsqueeze(Testing.data,1)/255\n",
    "testing_values = torch.LongTensor(Testing.targets)\n",
    "\n",
    "\n",
    "TrDataset = TensorDataset(training,training_values)\n",
    "ValDataset = TensorDataset(testing,testing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4702e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingL = DataLoader(TrDataset,batch_size=training.shape[0])\n",
    "ValidationL = DataLoader(ValDataset,batch_size=testing.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6904277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CifarModel, self).__init__()\n",
    "        \n",
    "        self.con_1 = nn.Conv2d(1,4,2)\n",
    "        \n",
    "        self.con_2 = nn.Conv2d(4,8,2)\n",
    "        \n",
    "        self.con_3 = nn.Conv2d(8,16,2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fl_1 = nn.Linear(64,128)\n",
    "        \n",
    "        self.fl_2 = nn.Linear(128,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.con_1(x),2))\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.con_2(x),2))\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.con_3(x),2))\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = F.relu(self.fl_1(x))\n",
    "        \n",
    "        return (self.fl_2(x))\n",
    "\n",
    "net = CifarModel()\n",
    "lossfun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=.01)\n",
    "lossf = []       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4d623f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch done 0 2.305208444595337\n",
      "Epoch done 1 2.2944133281707764\n",
      "Epoch done 2 2.2786543369293213\n",
      "Epoch done 3 2.247739553451538\n",
      "Epoch done 4 2.1941676139831543\n",
      "Epoch done 5 2.1106960773468018\n",
      "Epoch done 6 1.9881941080093384\n",
      "Epoch done 7 1.8324339389801025\n",
      "Epoch done 8 1.6643372774124146\n",
      "Epoch done 9 1.503933072090149\n",
      "Epoch done 10 1.3635271787643433\n",
      "Epoch done 11 1.2671631574630737\n",
      "Epoch done 12 1.2228515148162842\n",
      "Epoch done 13 1.206112027168274\n",
      "Epoch done 14 1.1984188556671143\n",
      "Epoch done 15 1.2180986404418945\n",
      "Epoch done 16 1.1782255172729492\n",
      "Epoch done 17 1.1641920804977417\n",
      "Epoch done 18 1.1138347387313843\n",
      "Epoch done 19 1.0792938470840454\n",
      "Epoch done 20 1.0530115365982056\n",
      "Epoch done 21 1.0233585834503174\n",
      "Epoch done 22 1.0125690698623657\n",
      "Epoch done 23 0.9748550057411194\n",
      "Epoch done 24 0.9471327662467957\n",
      "Epoch done 25 0.9472151398658752\n",
      "Epoch done 26 0.9320971369743347\n",
      "Epoch done 27 0.9016083478927612\n",
      "Epoch done 28 0.8829106092453003\n",
      "Epoch done 29 0.8891180157661438\n",
      "Epoch done 30 0.8689813017845154\n",
      "Epoch done 31 0.8508060574531555\n",
      "Epoch done 32 0.8412354588508606\n",
      "Epoch done 33 0.8374699354171753\n",
      "Epoch done 34 0.81911301612854\n",
      "Epoch done 35 0.8094749450683594\n",
      "Epoch done 36 0.8008827567100525\n",
      "Epoch done 37 0.7907252311706543\n",
      "Epoch done 38 0.7818819284439087\n",
      "Epoch done 39 0.775103747844696\n",
      "Epoch done 40 0.7658106088638306\n",
      "Epoch done 41 0.7563681602478027\n",
      "Epoch done 42 0.7503822445869446\n",
      "Epoch done 43 0.7426721453666687\n",
      "Epoch done 44 0.733766496181488\n",
      "Epoch done 45 0.7273623943328857\n",
      "Epoch done 46 0.7210636138916016\n",
      "Epoch done 47 0.7131928205490112\n",
      "Epoch done 48 0.7069132924079895\n",
      "Epoch done 49 0.7002962231636047\n",
      "Epoch done 50 0.694832980632782\n",
      "Epoch done 51 0.6899726986885071\n",
      "Epoch done 52 0.6831907629966736\n",
      "Epoch done 53 0.6780632138252258\n",
      "Epoch done 54 0.6736376285552979\n",
      "Epoch done 55 0.6692909002304077\n",
      "Epoch done 56 0.6643656492233276\n",
      "Epoch done 57 0.6598922610282898\n",
      "Epoch done 58 0.654746413230896\n",
      "Epoch done 59 0.6514893174171448\n",
      "Epoch done 60 0.6470040082931519\n",
      "Epoch done 61 0.6441015601158142\n",
      "Epoch done 62 0.6412950158119202\n",
      "Epoch done 63 0.6454145312309265\n",
      "Epoch done 64 0.6445237398147583\n",
      "Epoch done 65 0.6357614398002625\n",
      "Epoch done 66 0.6316210031509399\n",
      "Epoch done 67 0.6319082975387573\n",
      "Epoch done 68 0.625231146812439\n",
      "Epoch done 69 0.6229494214057922\n",
      "Epoch done 70 0.6240289211273193\n",
      "Epoch done 71 0.6152737140655518\n",
      "Epoch done 72 0.615028977394104\n",
      "Epoch done 73 0.6162318587303162\n",
      "Epoch done 74 0.6084839701652527\n",
      "Epoch done 75 0.607324481010437\n",
      "Epoch done 76 0.6092302799224854\n",
      "Epoch done 77 0.6039493083953857\n",
      "Epoch done 78 0.6001991629600525\n",
      "Epoch done 79 0.6018229126930237\n",
      "Epoch done 80 0.5983943343162537\n",
      "Epoch done 81 0.5941954851150513\n",
      "Epoch done 82 0.5937747359275818\n",
      "Epoch done 83 0.5933089852333069\n",
      "Epoch done 84 0.58933424949646\n",
      "Epoch done 85 0.586415708065033\n",
      "Epoch done 86 0.5859737992286682\n",
      "Epoch done 87 0.585231602191925\n",
      "Epoch done 88 0.5824440121650696\n",
      "Epoch done 89 0.5796350240707397\n",
      "Epoch done 90 0.5780687928199768\n",
      "Epoch done 91 0.5769029259681702\n",
      "Epoch done 92 0.5753316283226013\n",
      "Epoch done 93 0.573002278804779\n",
      "Epoch done 94 0.5707667469978333\n",
      "Epoch done 95 0.5689810514450073\n",
      "Epoch done 96 0.5676524639129639\n",
      "Epoch done 97 0.5665473937988281\n",
      "Epoch done 98 0.5653295516967773\n",
      "Epoch done 99 0.5642735958099365\n",
      "Epoch done 100 0.56406170129776\n",
      "Epoch done 101 0.5693528056144714\n",
      "Epoch done 102 0.59659343957901\n",
      "Epoch done 103 0.6528872847557068\n",
      "Epoch done 104 0.6400914192199707\n",
      "Epoch done 105 0.5579201579093933\n",
      "Epoch done 106 0.6321191191673279\n",
      "Epoch done 107 0.5710647106170654\n",
      "Epoch done 108 0.5943639278411865\n",
      "Epoch done 109 0.5681008100509644\n",
      "Epoch done 110 0.5826716423034668\n",
      "Epoch done 111 0.5619893670082092\n",
      "Epoch done 112 0.5777623057365417\n",
      "Epoch done 113 0.5551320910453796\n",
      "Epoch done 114 0.5725314021110535\n",
      "Epoch done 115 0.5525943636894226\n",
      "Epoch done 116 0.5646551251411438\n",
      "Epoch done 117 0.5531660318374634\n",
      "Epoch done 118 0.5555558800697327\n",
      "Epoch done 119 0.5533924102783203\n",
      "Epoch done 120 0.5480980277061462\n",
      "Epoch done 121 0.5522673726081848\n",
      "Epoch done 122 0.5431217551231384\n",
      "Epoch done 123 0.5491010546684265\n",
      "Epoch done 124 0.5405417084693909\n",
      "Epoch done 125 0.5442894101142883\n",
      "Epoch done 126 0.5389146208763123\n",
      "Epoch done 127 0.5398034453392029\n",
      "Epoch done 128 0.536889910697937\n",
      "Epoch done 129 0.5362913608551025\n",
      "Epoch done 130 0.5345954895019531\n",
      "Epoch done 131 0.533552348613739\n",
      "Epoch done 132 0.5320072770118713\n",
      "Epoch done 133 0.5313296914100647\n",
      "Epoch done 134 0.5291715264320374\n",
      "Epoch done 135 0.5292229652404785\n",
      "Epoch done 136 0.5267646312713623\n",
      "Epoch done 137 0.5266414880752563\n",
      "Epoch done 138 0.5245105624198914\n",
      "Epoch done 139 0.5239474773406982\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(140):\n",
    "    \n",
    "  \n",
    "    \n",
    "    for X,y in TrainingL:\n",
    "        \n",
    "        yhat  = net(X)\n",
    "        loss = lossfun(yhat,y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    print(\"Epoch done\",epochs,loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5701bffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.26999926567078\n"
     ]
    }
   ],
   "source": [
    "x_1,y_1 = next(iter(ValidationL))\n",
    "yhat  = net(x_1)\n",
    "\n",
    "print(100*torch.mean((torch.argmax(yhat,axis=1) == y_1).float()).item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2822d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 2, 1,  ..., 8, 1, 7])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(yhat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e6e070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
